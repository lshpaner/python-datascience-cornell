{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cdbbd3faab2d9393",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Cleaning up Data\n",
    "\n",
    "Sometimes data comes to us in a form that requires some cleaning before we can begin with further analyses.  In this exercise we will explore some tools and strategies for that.\n",
    "\n",
    "We'll begin by reading in a modified version of the Ithaca climate dataset that we worked with previously.  You should notice that there is a new column in the dataframe, indicating the prevailing Sky conditions for each day (sunny, cloudy, etc.).\n",
    "\n",
    "Execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e5dc3163b139bcd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31 entries, 0 to 30\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Date                 31 non-null     object \n",
      " 1   Max T                30 non-null     float64\n",
      " 2   Minimum Temp         28 non-null     float64\n",
      " 3   Average Temperature  29 non-null     float64\n",
      " 4   Precipitation        31 non-null     float64\n",
      " 5   Snowfall             27 non-null     float64\n",
      " 6   Snow Depth           29 non-null     float64\n",
      " 7   Sky                  29 non-null     object \n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IthacaDailyClimateJan2018expanded.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f5884170056497f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at the dataframe in its entirety.  Execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-264f12ec86e30aab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Max T</th>\n",
       "      <th>Minimum Temp</th>\n",
       "      <th>Average Temperature</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>Snow Depth</th>\n",
       "      <th>Sky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>partly sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>party sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>partly sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>57.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>couldy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>partly sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>partly sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>46.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>50.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>party sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Max T  Minimum Temp  Average Temperature  Precipitation  \\\n",
       "0   2018-01-01    5.0           0.0                  2.5           0.04   \n",
       "1   2018-01-02   13.0           1.0                  7.0           0.03   \n",
       "2   2018-01-03   19.0          -2.0                  NaN           0.00   \n",
       "3   2018-01-04   22.0           1.0                 11.5           0.00   \n",
       "4   2018-01-05   18.0          -2.0                  8.0           0.09   \n",
       "5   2018-01-06    2.0          -3.0                 -0.5           0.00   \n",
       "6   2018-01-07    2.0          -3.0                 -0.5           0.00   \n",
       "7   2018-01-08   24.0          -3.0                 10.5           0.00   \n",
       "8   2018-01-09   37.0          23.0                 30.0           0.00   \n",
       "9   2018-01-10   33.0          15.0                 24.0           0.00   \n",
       "10  2018-01-11   41.0          18.0                 29.5           0.00   \n",
       "11  2018-01-12   57.0          40.0                 48.5           0.76   \n",
       "12  2018-01-13   62.0          12.0                 37.0           0.94   \n",
       "13  2018-01-14   12.0           4.0                  8.0           0.06   \n",
       "14  2018-01-15   12.0          -9.0                  1.5           0.00   \n",
       "15  2018-01-16   22.0           NaN                  6.5           0.05   \n",
       "16  2018-01-17   26.0          15.0                 20.5           0.13   \n",
       "17  2018-01-18   20.0          -1.0                  9.5           0.00   \n",
       "18  2018-01-19   22.0           NaN                  NaN           0.00   \n",
       "19  2018-01-20   37.0           8.0                 22.5           0.00   \n",
       "20  2018-01-21   45.0          16.0                 30.5           0.00   \n",
       "21  2018-01-22    NaN          19.0                 30.5           0.02   \n",
       "22  2018-01-23   46.0          35.0                 40.5           0.01   \n",
       "23  2018-01-24   50.0          24.0                 37.0           0.10   \n",
       "24  2018-01-25   25.0          16.0                 20.5           0.02   \n",
       "25  2018-01-26   24.0          13.0                 18.5           0.00   \n",
       "26  2018-01-27   38.0          13.0                 25.5           0.00   \n",
       "27  2018-01-28   51.0           NaN                 40.5           0.02   \n",
       "28  2018-01-29   46.0          21.0                 33.5           0.00   \n",
       "29  2018-01-30   37.0          19.0                 28.0           0.05   \n",
       "30  2018-01-31   19.0          -2.0                  8.5           0.06   \n",
       "\n",
       "    Snowfall  Snow Depth             Sky  \n",
       "0        1.0         3.0          cloudy  \n",
       "1        NaN         4.0   partly cloudy  \n",
       "2        0.0         NaN           sunny  \n",
       "3        0.0         3.0    partly sunny  \n",
       "4        1.2         4.0          cloudy  \n",
       "5        0.0         4.0     party sunny  \n",
       "6        0.0         4.0    partly sunny  \n",
       "7        0.0         4.0           sunny  \n",
       "8        0.0         4.0           sunny  \n",
       "9        0.0         4.0           sunny  \n",
       "10       0.0         3.0           sunny  \n",
       "11       0.0         0.0             NaN  \n",
       "12       6.0         6.0          couldy  \n",
       "13       0.9         6.0   partly cloudy  \n",
       "14       0.0         6.0    partly sunny  \n",
       "15       0.5         6.0          cloudy  \n",
       "16       1.6         8.0          cloudy  \n",
       "17       0.0         NaN           sunny  \n",
       "18       0.0         7.0           sunny  \n",
       "19       0.0         6.0             NaN  \n",
       "20       0.0         4.0    partly sunny  \n",
       "21       0.0         3.0   partly cloudy  \n",
       "22       0.0         0.0   partly cloudy  \n",
       "23       0.0         0.0          cloudy  \n",
       "24       NaN         1.0          cloudy  \n",
       "25       NaN         0.0           sunny  \n",
       "26       NaN         0.0           sunny  \n",
       "27       0.0         0.0     party sunny  \n",
       "28       0.0         0.0           sunny  \n",
       "29       0.5         1.0          cloudy  \n",
       "30       0.8         1.0          cloudy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3a61fc63c03408c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 1.\n",
    "\n",
    "Let's examine the column names in a bit more detail.  Execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ab9c990eb410c23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Max T', 'Minimum Temp', 'Average Temperature', 'Precipitation',\n",
       "       'Snowfall', 'Snow Depth', 'Sky'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are three different temperature columns, but the naming conventions differ for all three: \"Max T\", \"Minimum Temp\", and \"Average Temperature\".  This can lead to confusion because you need to keep track in your mind how temperature is labeled in each column name (T, Temp, Temperature).  Furthermore, the largest temperature is labeled with the shorthand \"Max\", while the smallest temperature is labeled with the full word \"Minimum\".  While we are free to choose whatever names we want for our data (within any syntactic rules), it is useful &mdash; for both you the developer and for anyone else who might be using the code &mdash; to establish some uniformity and consistency in naming.  Fortunately, we don't need to go back and modify the original csv file; we can just modify the column names in our code.\n",
    "\n",
    "In the code cell below, use the ```rename``` method on a dataframe to rename the columns as follows:\n",
    "\n",
    "* rename 'Max T' to be 'Maximum Temperature'\n",
    "* rename 'Minimum Temp' to be 'Minimum Temperature'\n",
    "\n",
    "Consult the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) for ```df.rename``` and find an example to \"Rename columns using a mapping\", which will demonstrate how to pass a dictionary to the method in order to change the column names. Hint: each element in the dictionary is a key/value pair in which the key is the original name and the value is the new name. For example: {original_name: new_name}.\n",
    "\n",
    "Note that the ```rename``` method will, by default, return a new dataframe with the modified names.  You can either assign that new dataframe to a variable (you can even just reassign it to the name ```df```) or you can use the ```inplace=True``` option to modify ```df``` directly. \n",
    "\n",
    "For this exercise, you will use the ```inplace=True``` option in the `rename` method to modify ```df``` directly. After you've done the renaming, inspect the column names of the dataframe to verify that you've changed the names as intended (and if necessary, modify your renaming code until the column names are as desired.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 50% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bb8a703d567874f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Maximum Temperature  Minimum Temperature  Average Temperature  \\\n",
      "0   2018-01-01                  5.0                  0.0                  2.5   \n",
      "1   2018-01-02                 13.0                  1.0                  7.0   \n",
      "2   2018-01-03                 19.0                 -2.0                  NaN   \n",
      "3   2018-01-04                 22.0                  1.0                 11.5   \n",
      "4   2018-01-05                 18.0                 -2.0                  8.0   \n",
      "5   2018-01-06                  2.0                 -3.0                 -0.5   \n",
      "6   2018-01-07                  2.0                 -3.0                 -0.5   \n",
      "7   2018-01-08                 24.0                 -3.0                 10.5   \n",
      "8   2018-01-09                 37.0                 23.0                 30.0   \n",
      "9   2018-01-10                 33.0                 15.0                 24.0   \n",
      "10  2018-01-11                 41.0                 18.0                 29.5   \n",
      "11  2018-01-12                 57.0                 40.0                 48.5   \n",
      "12  2018-01-13                 62.0                 12.0                 37.0   \n",
      "13  2018-01-14                 12.0                  4.0                  8.0   \n",
      "14  2018-01-15                 12.0                 -9.0                  1.5   \n",
      "15  2018-01-16                 22.0                  NaN                  6.5   \n",
      "16  2018-01-17                 26.0                 15.0                 20.5   \n",
      "17  2018-01-18                 20.0                 -1.0                  9.5   \n",
      "18  2018-01-19                 22.0                  NaN                  NaN   \n",
      "19  2018-01-20                 37.0                  8.0                 22.5   \n",
      "20  2018-01-21                 45.0                 16.0                 30.5   \n",
      "21  2018-01-22                  NaN                 19.0                 30.5   \n",
      "22  2018-01-23                 46.0                 35.0                 40.5   \n",
      "23  2018-01-24                 50.0                 24.0                 37.0   \n",
      "24  2018-01-25                 25.0                 16.0                 20.5   \n",
      "25  2018-01-26                 24.0                 13.0                 18.5   \n",
      "26  2018-01-27                 38.0                 13.0                 25.5   \n",
      "27  2018-01-28                 51.0                  NaN                 40.5   \n",
      "28  2018-01-29                 46.0                 21.0                 33.5   \n",
      "29  2018-01-30                 37.0                 19.0                 28.0   \n",
      "30  2018-01-31                 19.0                 -2.0                  8.5   \n",
      "\n",
      "    Precipitation  Snowfall  Snow Depth             Sky  \n",
      "0            0.04       1.0         3.0          cloudy  \n",
      "1            0.03       NaN         4.0   partly cloudy  \n",
      "2            0.00       0.0         NaN           sunny  \n",
      "3            0.00       0.0         3.0    partly sunny  \n",
      "4            0.09       1.2         4.0          cloudy  \n",
      "5            0.00       0.0         4.0     party sunny  \n",
      "6            0.00       0.0         4.0    partly sunny  \n",
      "7            0.00       0.0         4.0           sunny  \n",
      "8            0.00       0.0         4.0           sunny  \n",
      "9            0.00       0.0         4.0           sunny  \n",
      "10           0.00       0.0         3.0           sunny  \n",
      "11           0.76       0.0         0.0             NaN  \n",
      "12           0.94       6.0         6.0          couldy  \n",
      "13           0.06       0.9         6.0   partly cloudy  \n",
      "14           0.00       0.0         6.0    partly sunny  \n",
      "15           0.05       0.5         6.0          cloudy  \n",
      "16           0.13       1.6         8.0          cloudy  \n",
      "17           0.00       0.0         NaN           sunny  \n",
      "18           0.00       0.0         7.0           sunny  \n",
      "19           0.00       0.0         6.0             NaN  \n",
      "20           0.00       0.0         4.0    partly sunny  \n",
      "21           0.02       0.0         3.0   partly cloudy  \n",
      "22           0.01       0.0         0.0   partly cloudy  \n",
      "23           0.10       0.0         0.0          cloudy  \n",
      "24           0.02       NaN         1.0          cloudy  \n",
      "25           0.00       NaN         0.0           sunny  \n",
      "26           0.00       NaN         0.0           sunny  \n",
      "27           0.02       0.0         0.0     party sunny  \n",
      "28           0.00       0.0         0.0           sunny  \n",
      "29           0.05       0.5         1.0          cloudy  \n",
      "30           0.06       0.8         1.0          cloudy  \n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'Max T':'Maximum Temperature','Minimum Temp': 'Minimum Temperature'},inplace=True )\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check\n",
    "\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Dataframe df contains column 'Maximum Temperature'.\n",
      "Correct!\n",
      "Dataframe df contains column 'Minimum Temperature'.\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testChangeNameMax, testChangeNameMin\n",
    "\n",
    "try:\n",
    "    print(testChangeNameMax(df))    \n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    \n",
    "try:\n",
    "    print(testChangeNameMin(df))    \n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below and inspect the column names of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9d37d494c9c479b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Maximum Temperature', 'Minimum Temperature',\n",
       "       'Average Temperature', 'Precipitation', 'Snowfall', 'Snow Depth',\n",
       "       'Sky'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-716ba93fdae97de6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 2.\n",
    "\n",
    "Let's examine the new data in the 'Sky' column.  The entries here are strings representing categorical data, such as \"sunny\", \"partly sunny\", \"cloudy\" and \"partly cloudy\".  Because they are text-based, it is often useful to verify that there are no mispellings or spelling variants.  A useful method on a Series, or on a column extracted from a DataFrame, is ```unique```, which returns an array of unique entries in that Series or column.\n",
    "\n",
    "In the code cell below, write and evaluate an expression to extract the unique entries of the 'Sky' column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be2bc1e7e1d28876",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cloudy', 'partly cloudy', 'sunny', 'partly sunny', 'party sunny',\n",
       "       nan, 'couldy', ' partly cloudy'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sky'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01d49315735332e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "While it might not have been obvious when looking at the entire dataframe, extracting the group of unique entries in the 'Sky' column makes it obvious that there are some misspellings and other textual problems, such as an extra space at the beginning of ' partly cloudy'.\n",
    "\n",
    "Pandas dataframes have a ```replace``` method that allows you to change values in a dataframe according to a specified rule, as described [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html).  If you want to replace text entries (strings), you either need to provide the full string to replace, or use the ```regex=True``` option to specify a regular expression (regex) for replacing part of a string.  In this exercise, let's just specify fully the strings we want to replace.  Note that the ```replace``` method is for changing values in the body of the dataframe, whereas the ```rename``` method used above is for changing the names of the index or column labels.  When called on an entire dataframe, the ```replace``` method will replace all instances of the specified text, regardless of what column it is in.  (If you wanted to replace values only in a particular column, you would first extract that column before doing the replacement.)\n",
    "\n",
    "In the code cell below, write and evaluate code to replace all the misspelled entries in the dataframe with their corrected versions.  The easiest way to do this is to provide all the corrections in a dictionary which is passed as an argument to the method.  Note that by default, the ```replace``` method will return a new dataframe, so you can either assign it to a variable, or modify the original dataframe in place by using the `inplace=True` option.\n",
    "\n",
    "For this exercise, you will modify `df` in place by using the `inplace=True` option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Cell\n",
    "\n",
    "This cell is worth 50% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1ef5a25413d2262",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.replace({'party sunny':'partly sunny', 'couldy': 'cloudy', ' partly cloudy':'partly cloudy'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Check\n",
    "\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "'party sunny' was corrected.\n",
      "Correct!\n",
      "'couldy' was corrected.\n",
      "Correct!\n",
      "' partly cloudly' was corrected.\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testChangePartlySunny, testChangeCloudy, testChangePartlyCloudy\n",
    "\n",
    "try:\n",
    "    print(testChangePartlySunny(df))    \n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    \n",
    "try:\n",
    "    print(testChangeCloudy(df))    \n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    \n",
    "try:\n",
    "    print(testChangePartlyCloudy(df))    \n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91d2ae7a9956b9ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After doing the text replacement, re-examine the unique entries of the 'Sky' column to verify that you have corrected the problems with the original data.  (There should be 5 unique entries.)  If you have not fixed all the problems, modify your replacement code above and continue until the data are corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-985ae70cb35ed2fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cloudy', 'partly cloudy', 'sunny', 'partly sunny', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sky'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
